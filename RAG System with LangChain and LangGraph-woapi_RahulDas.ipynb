{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOKkQANIUMJ3r0Tb3DePQFL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Introduction**"],"metadata":{"id":"Gg1yZ7wDhmuE"}},{"cell_type":"markdown","source":["Retrieval-Augmented Generation (RAG) is a powerful approach that enhances large language models by grounding their responses in real, external knowledge. Instead of relying only on what the model has learned during training, RAG retrieves relevant information from a knowledge base and uses it to generate accurate, reliable answers.\n","\n","In this project, we use LangChain and LangGraph to build a modular and transparent RAG pipeline. LangChain handles document loading, chunking, embeddings, and retrieval, while LangGraph structures the workflow into clear nodes such as retrieval and generation. Together, they create a flexible, efficient, and scalable system capable of answering questions based on custom knowledge sources. This setup forms a strong foundation for practical applications like chatbots, enterprise search, support assistants, and domain-specific AI tools."],"metadata":{"id":"R9vMQGe7hoPp"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5loAegQYhJUo","executionInfo":{"status":"ok","timestamp":1762522128084,"user_tz":-330,"elapsed":4094,"user":{"displayName":"Rahul Das","userId":"10605675281746257009"}},"outputId":"9fcb13fe-ee3b-47e8-9177-6b2f248d3677"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/Projects/Tools for Generative AI/RAG System with LangChain and LangGraph')"],"metadata":{"id":"59Gc0xMGhb3n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install -U langchain langchain-community langchain-openai langchain-pinecone"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEZkbtYCbpH2","executionInfo":{"status":"ok","timestamp":1762522140969,"user_tz":-330,"elapsed":12882,"user":{"displayName":"Rahul Das","userId":"10605675281746257009"}},"outputId":"bcb58463-be71-4dd6-b09a-1e0e23705249"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.0.4)\n","Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n","Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.0.2)\n","Requirement already satisfied: langchain-pinecone in /usr/local/lib/python3.12/dist-packages (0.2.13)\n","Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.3)\n","Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.2)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n","Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n","Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n","Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n","Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n","Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n","Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.40)\n","Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n","Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.3.4)\n","Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n","Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n","Requirement already satisfied: pinecone<8.0.0,>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (7.3.0)\n","Requirement already satisfied: httpx>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from langchain-pinecone) (0.28.1)\n","Requirement already satisfied: simsimd>=5.9.11 in /usr/local/lib/python3.12/dist-packages (from langchain-pinecone) (6.5.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain-pinecone) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain-pinecone) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain-pinecone) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain-pinecone) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.0->langchain-pinecone) (0.16.0)\n","Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (24.2)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n","Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n","Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.2)\n","Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n","Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n","Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.8.0)\n","Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (0.0.7)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.9.0.post0)\n","Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.5.0)\n","Requirement already satisfied: aiohttp-retry<3.0.0,>=2.9.1 in /usr/local/lib/python3.12/dist-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.9.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n","Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.17.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"]}]},{"cell_type":"markdown","source":["**Set your API key**"],"metadata":{"id":"Fi5I4tqWivJx"}},{"cell_type":"code","source":["import os\n","\n","os.environ[\"OPENAI_API_KEY\"] = \"Your API Key\""],"metadata":{"id":"3Ba3Vl4jgyHA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Load your KB + Split into chunks**"],"metadata":{"id":"RXQNw2Swi0Px"}},{"cell_type":"code","source":["import json\n","from langchain_core.documents import Document\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","\n","with open(\"knowledge_base.json\", \"r\") as f:\n","    items = json.load(f)\n","\n","docs = [\n","    Document(page_content=item[\"text\"], metadata={\"id\": item.get(\"id\", i)})\n","    for i, item in enumerate(items)\n","]\n","\n","splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=200)\n","chunks = splitter.split_documents(docs)\n","print(\"✅ Chunks created:\", len(chunks))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I_lxA2KyhBny","executionInfo":{"status":"ok","timestamp":1762522325197,"user_tz":-330,"elapsed":55,"user":{"displayName":"Rahul Das","userId":"10605675281746257009"}},"outputId":"7a3db677-8cb2-4fcc-e631-0659470243ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Chunks created: 10\n"]}]},{"cell_type":"markdown","source":["**Build vector_store**"],"metadata":{"id":"hy--0l7zi34g"}},{"cell_type":"code","source":["from langchain_openai import OpenAIEmbeddings\n","from langchain_core.vectorstores import InMemoryVectorStore\n","\n","embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n","vector_store = InMemoryVectorStore(embeddings)\n","\n","vector_store.add_documents(chunks)\n","\n","print(\"✅ Vector store ready with\", len(chunks), \"chunks.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xykjsF5ihHW4","executionInfo":{"status":"ok","timestamp":1762522333848,"user_tz":-330,"elapsed":1686,"user":{"displayName":"Rahul Das","userId":"10605675281746257009"}},"outputId":"d5d8a68f-a726-4751-8ba1-4e029594fa02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Vector store ready with 10 chunks.\n"]}]},{"cell_type":"markdown","source":["**Build LangGraph**"],"metadata":{"id":"aNWGZt8_i78X"}},{"cell_type":"code","source":["from typing_extensions import TypedDict, List\n","from langchain_core.documents import Document\n","from langgraph.graph import StateGraph, END\n","from langchain_openai import ChatOpenAI\n","\n","# ---- State\n","class State(TypedDict):\n","    question: str\n","    context: List[Document]\n","    answer: str\n","\n","llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n","\n","# ---- Nodes\n","def retrieve(state: State):\n","    retrieved_docs = vector_store.similarity_search(state[\"question\"], k=5)\n","    return {\"context\": retrieved_docs}\n","\n","def format_context(docs):\n","    return \"\\n\\n\".join([d.page_content for d in docs])\n","\n","def generate(state: State):\n","    ctx = format_context(state[\"context\"])\n","    q = state[\"question\"]\n","    msg = f\"Use ONLY the context to answer.\\n\\nContext:\\n{ctx}\\n\\nQuestion: {q}\\nAnswer:\"\n","    out = llm.invoke(msg).content\n","    return {\"answer\": out}\n","\n","# ---- Graph\n","graph_obj = StateGraph(State)\n","graph_obj.add_node(\"retrieve\", retrieve)\n","graph_obj.add_node(\"generate\", generate)\n","\n","graph_obj.set_entry_point(\"retrieve\")\n","graph_obj.add_edge(\"retrieve\", \"generate\")\n","graph_obj.add_edge(\"generate\", END)\n","\n","graph = graph_obj.compile()\n"],"metadata":{"id":"zYSIWRWJhJYI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Chat Loop**"],"metadata":{"id":"0pUHfANPjAnA"}},{"cell_type":"code","source":["while True:\n","    question = input(\"Ask a question (or type 'exit'): \")\n","    if question.lower() == \"exit\":\n","        break\n","\n","    response = graph.invoke({\"question\": question})\n","    print(\"\\n✅ ANSWER:\\n\", response[\"answer\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQCU2xrxhLZ_","executionInfo":{"status":"ok","timestamp":1762522362440,"user_tz":-330,"elapsed":13828,"user":{"displayName":"Rahul Das","userId":"10605675281746257009"}},"outputId":"bd29dccc-67da-4578-f249-96fd254bfa5a"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Ask a question (or type 'exit'): Rag\n","\n","✅ ANSWER:\n"," RAG, or Retrieval-Augmented Generation, combines document retrieval with large language model (LLM) generation to provide accurate and grounded answers. It involves evaluating metrics such as relevance, groundedness, hallucination rate, and latency, with common metrics including Recall@k and citation accuracy. A vector database is used to store embeddings and enable fast similarity search, which is essential for RAG systems.\n","Ask a question (or type 'exit'): exit\n"]}]},{"cell_type":"markdown","source":["**Conclusion**"],"metadata":{"id":"8p65U3rihePx"}},{"cell_type":"markdown","source":["This project successfully demonstrates how Retrieval-Augmented Generation (RAG) can be built using LangChain and LangGraph to create a smarter, more reliable question-answering system. By combining document chunking, embedding-based retrieval, and LLM generation, the system provides accurate, context-grounded answers while reducing hallucinations. LangGraph’s node-based workflow makes the entire pipeline modular, transparent, and easy to extend. Overall, this RAG system forms a strong foundation for building advanced AI assistants, knowledge bots, and enterprise search applications."],"metadata":{"id":"vtHlQg6ohffo"}},{"cell_type":"code","source":[],"metadata":{"id":"CBr8e59nhe64"},"execution_count":null,"outputs":[]}]}